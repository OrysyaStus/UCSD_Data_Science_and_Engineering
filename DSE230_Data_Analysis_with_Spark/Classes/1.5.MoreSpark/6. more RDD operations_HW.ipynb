{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "509a64d15ec6b6a3d9baa83e52bb42e5",
     "grade": false,
     "grade_id": "1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Setup Data for Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d59120ba4cea2f36607c31a08bb9258e",
     "grade": false,
     "grade_id": "2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### <span style=\"color:red\">IMPORTANT: Only modify cells which have the following comment:</span>\n",
    "```python\n",
    "# Modify this cell\n",
    "```\n",
    "##### <span style=\"color:red\">Do not add any new cells when you submit the homework</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e93a4d4a928a23f690dfadea1f2c14d5",
     "grade": false,
     "grade_id": "3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "First we import necessary files and create the spark context. Then we load in the dataset we will be working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4a6832f33276e527076a6da993f09323",
     "grade": false,
     "grade_id": "4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "92fde33aa88843c9b99366068b4b867b",
     "grade": false,
     "grade_id": "5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(master=\"local[4]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c0d7e9d6a2692942130001c93328cb9c",
     "grade": false,
     "grade_id": "6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import Tester.moreRDD as moreRDD\n",
    "pickleFile=\"Tester/moreRDD.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "eb9facfa9d7ea3476f031985b7922a67",
     "grade": false,
     "grade_id": "7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import Tester.moreRDD as moreRDD\n",
    "data = moreRDD.getData(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "16f06fd04138682ba273d8006747c253",
     "grade": false,
     "grade_id": "9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Code for getData():\n",
      "def getData(sc):\n",
      "    f = urllib.urlretrieve (\"http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\", \"kddcup.data_10_percent.gz\")\n",
      "    data_file = \"./kddcup.data_10_percent.gz\"\n",
      "    return sc.textFile(data_file)\n",
      "\n",
      "Number of Variables: 494021\n",
      "\n",
      "Variable Exampe:\n",
      "[u'0,tcp,http,SF,181,5450,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,8,8,0.00,0.00,0.00,0.00,1.00,0.00,0.00,9,9,1.00,0.00,0.11,0.00,0.00,0.00,0.00,0.00,normal.']\n"
     ]
    }
   ],
   "source": [
    "print \"Python Code for getData():\"\n",
    "import inspect\n",
    "for i in inspect.getsourcelines(moreRDD.getData)[0]:\n",
    "    print i[:-1]\n",
    "print\n",
    "print \"Number of Variables: \"+str( data.count() )\n",
    "print \"\\nVariable Exampe:\"\n",
    "print data.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "41e6202faaa083e9cd03fb79afe36d46",
     "grade": false,
     "grade_id": "10",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Exercise 1\n",
    "Write a function **csv_to_kv** to map each row in `data` to a key-value pair where the key is the last element in the row (network interaction type) and the value is a list of all of the elements in the row. Return the resulting RDD.\n",
    "\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "print csv_to_kv(data).take(1)\n",
    "```\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    "```python\n",
    "[(u'normal.', [u'0', u'tcp', u'http', u'SF', u'181', u'5450', u'0', u'0', u'0', u'0', u'0', u'1', u'0', u'0', u'0', u'0', u'0', u'0', u'0', u'0', u'0', u'0', u'8', u'8', u'0.00', u'0.00', u'0.00', u'0.00', u'1.00', u'0.00', u'0.00', u'9', u'9', u'1.00', u'0.00', u'0.11', u'0.00', u'0.00', u'0.00', u'0.00', u'0.00', u'normal.'])]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "def csv_to_kv(data):\n",
    "    KV = data.map(lambda x: x.split(\",\"))\\\n",
    "        .map(lambda x: (x[-1], x))\n",
    "    return KV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7b18a7fbda986b660295c7a45f957c3f",
     "grade": true,
     "grade_id": "ex1",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <class 'pyspark.rdd.RDD'>\n",
      "Correct Output: [(u'normal.', [u'0', u'tcp', u'http', u'SF', u'181', u'5450', u'0', u'0', u'0', u'0', u'0', u'1', u'0', u'0', u'0', u'0', u'0', u'0', u'0', u'0', u'0', u'0', u'8', u'8', u'0.00', u'0.00', u'0.00', u'0.00', u'1.00', u'0.00', u'0.00', u'9', u'9', u'1.00', u'0.00', u'0.11', u'0.00', u'0.00', u'0.00', u'0.00', u'0.00', u'normal.']), (u'normal.', [u'0', u'tcp', u'http', u'SF', u'239', u'486', u'0', u'0', u'0', u'0', u'0', u'1', u'0', u'0', u'0', u'0', u'0', u'0', u'0', u'0', u'0', u'0', u'8', u'8', u'0.00', u'0.00', u'0.00', u'0.00', u'1.00', u'0.00', u'0.00', u'19', u'19', u'1.00', u'0.00', u'0.05', u'0.00', u'0.00', u'0.00', u'0.00', u'0.00', u'normal.']), (u'normal.', [u'0', u'tcp', u'http', u'SF', u'235', u'1337', u'0', u'0', u'0', u'0', u'0', u'1', u'0', u'0', u'0', u'0', u'0', u'0', u'0', u'0', u'0', u'0', u'8', u'8', u'0.00', u'0.00', u'0.00', u'0.00', u'1.00', u'0.00', u'0.00', u'29', u'29', u'1.00', u'0.00', u'0.03', u'0.00', u'0.00', u'0.00', u'0.00', u'0.00', u'normal.'])]\n",
      "Great Job!\n"
     ]
    }
   ],
   "source": [
    "import Tester.moreRDD as moreRDD\n",
    "moreRDD.exercise1(pickleFile, csv_to_kv, data ,sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "080a045aff94fb60ae71760d10337bd9",
     "grade": false,
     "grade_id": "11",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Exercise 2\n",
    "Create a new function **orderNet**, that returns an RDD of the sorted network interaction types by total duration. Duration is the first column of x, i.e. x[0]. Your RDD should contain tuples of the form: (interaction_type, total_duration).\n",
    "\n",
    "    Note: You will want to use csv_to_kv from exercise 1 \n",
    "\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "print orderNet(data).take(5)\n",
    "\n",
    "```\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    "`\n",
    "[(u'normal.', 21075991), (u'portsweep.', 1991911), (u'warezclient.', 627563), (u'buffer_overflow.', 2751), (u'multihop.', 1288)]\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "def orderNet(data):\n",
    "    RDD = csv_to_kv(data)  #<-- The correct RDD from csv_to_kv(data)\n",
    "    orderedRDD = RDD.map(lambda x: (x[0], int(x[1][0])))\\\n",
    "        .reduceByKey(lambda x,y: x+y)\\\n",
    "        .map(lambda (k,v): (v, k))\\\n",
    "        .sortByKey(False)\\\n",
    "        .map(lambda (v,k): (k,v))\n",
    "    return orderedRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8155a6a20ae7c618399caa10d29e1529",
     "grade": true,
     "grade_id": "ex2",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <class 'pyspark.rdd.RDD'>\n",
      "Correct Output: [(u'normal.', 21075991), (u'portsweep.', 1991911), (u'warezclient.', 627563), (u'buffer_overflow.', 2751), (u'multihop.', 1288)]\n",
      "Great Job!\n"
     ]
    }
   ],
   "source": [
    "import Tester.moreRDD as moreRDD\n",
    "moreRDD.exercise2(pickleFile, orderNet, data ,sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1b2d4b14c7c67dcfd13edcc8839bf08c",
     "grade": false,
     "grade_id": "12",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Exercise 3\n",
    "\n",
    "Continue with the functions created in previous exercises. Create a function, **avgDuration**, that calculates and returns the average duration for each of the network interaction types. Order the data by key name. You are encouraged to use **combineByKey()**.\n",
    "\n",
    "    Note: You will want to use functions from the previous exercises\n",
    "\n",
    "\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "print avgDuration(data).take(9)\n",
    "```\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    "`\n",
    "[(u'back.', 0.1289151157512483), (u'buffer_overflow.', 91.7), (u'ftp_write.', 32.375), (u'guess_passwd.', 2.7169811320754715), (u'imap.', 6.0), (u'ipsweep.', 0.034482758620689655), (u'land.', 0.0), (u'loadmodule.', 36.22222222222222), (u'multihop.', 184.0)]\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "def avgDuration(data):\n",
    "    RDD1 = csv_to_kv(data)  #<-- The correct RDD from csv_to_kv(data)\n",
    "    RDD = RDD1.map(lambda x: (x[0], int(x[1][0])))\n",
    "    RDD2 = orderNet(data)   #<-- The correct RDD from orderNet(data)\n",
    "    \n",
    "    sumCount = RDD.combineByKey(lambda value: (value, 1),\n",
    "                                lambda x, value: (x[0] + value, x[1] + 1),\n",
    "                                lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "    \n",
    "    avgRDD = sumCount.map(lambda (label, (value_sum, count)): (label, value_sum*1.0 / count))\\\n",
    "        .sortBy(ascending=1, keyfunc=lambda x: x[0])\n",
    "    return avgRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "35498fedf1dfa9f00d07add08db0ccc1",
     "grade": true,
     "grade_id": "ex3",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <class 'pyspark.rdd.RDD'>\n",
      "Correct Output: [(u'back.', 0.1289151157512483), (u'buffer_overflow.', 91.7), (u'ftp_write.', 32.375), (u'guess_passwd.', 2.7169811320754715), (u'imap.', 6.0), (u'ipsweep.', 0.034482758620689655), (u'land.', 0.0), (u'loadmodule.', 36.22222222222222), (u'multihop.', 184.0)]\n",
      "Great Job!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Tester.moreRDD as moreRDD\n",
    "moreRDD.exercise3(pickleFile, avgDuration, data ,sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c3dc291a5393a6f5943eb2b0efbb3896",
     "grade": false,
     "grade_id": "13",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "192px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
