{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "256be925e1ac2c20b5ab673064b06652",
     "grade": false,
     "grade_id": "r1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Setup Notebook for Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2d72124b8b8b7912fc81741aac8df6a1",
     "grade": false,
     "grade_id": "r2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "##### <span style=\"color:red\">IMPORTANT: Only modify cells which have the following comment:</span>\n",
    "```python\n",
    "# Modify this cell\n",
    "```\n",
    "##### <span style=\"color:red\">Do not add any new cells when you submit the homework</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "df20595a79a3974e238ddaa7cb4d5f3c",
     "grade": false,
     "grade_id": "r3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7ca7393082f42efd9e2175acff15b3ba",
     "grade": false,
     "grade_id": "r4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc=SparkContext(master=\"local[4]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6038be84bab50376d26837c931521955",
     "grade": false,
     "grade_id": "r5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import Tester.SparkBasics1 as SparkBasics1\n",
    "pickleFile=\"Tester/SparkBasics1.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "220968c71bd17202be296e3eb0d9f6f8",
     "grade": false,
     "grade_id": "r6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Importing all packages necessary to complete the homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8add22aecc9b4d22dfd7a6b009cc5ab5",
     "grade": false,
     "grade_id": "r7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f65ce84ea6762f8e645dd37c17485884",
     "grade": false,
     "grade_id": "Excercise1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Exercise 1\n",
    "\n",
    "Write a function called **mapcos** that has a single paramater: an RDD of numbers. Use **map** to return an RRD that is the `cos()` (cosine) of the input.\n",
    "\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "A=sc.parallelize( range(3) )\n",
    "print mapcos(A)\n",
    "print mapcos(A).collect()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    "PythonRDD[14] at RDD at PythonRDD.scala:48\n",
    "\n",
    "[1.0, 0.54030..., -0.41614...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "def mapcos(A):\n",
    "    RDD = A.map(lambda x: np.cos(x))\n",
    "    return RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4f3423b57b423cd352c053dc8cb6b3a6",
     "grade": true,
     "grade_id": "ex_1",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0, 1, 2]\n",
      "Correct Output: [1.0, 0.54030230586813977, -0.41614683654714241]\n",
      "Great Job!\n",
      "\n",
      "Input: [4, 5, 6, 7, 8, 9, 10, 11]\n",
      "Correct Output: [-0.65364362086361194, 0.28366218546322625, 0.96017028665036597, 0.7539022543433046, -0.14550003380861354, -0.91113026188467694, -0.83907152907645244, 0.0044256979880507854]\n",
      "Great Job!\n",
      "\n",
      "Input: [-4, -3, -2, -1]\n",
      "Correct Output: [-0.65364362086361194, -0.98999249660044542, -0.41614683654714241, 0.54030230586813977]\n",
      "Great Job!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import Tester.SparkBasics1 as SparkBasics1\n",
    "SparkBasics1.exercise1_1(pickleFile, mapcos ,sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "462802cefbb3134799228e9a14a92772",
     "grade": false,
     "grade_id": "r8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Exercise 2\n",
    "\n",
    "Write a function called **mapwords** that has a single paramater: an RDD of strings, and returns an RDD that contains a list of words for each string.\n",
    "\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "stringRDD=sc.parallelize([\"Spring quarter\", \"Learning spark basics\", \"Big data analytics with Spark\"])\n",
    "print mapwords(stringRDD).collect()\n",
    "```\n",
    "\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    "[['Spring', 'quarter'], ['Learning', 'spark', 'basics'], ['Big', 'data', 'analytics', 'with', 'Spark']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "def mapwords(stringRDD):\n",
    "    RDD = stringRDD.map(lambda x: x.split(\" \"))\n",
    "    return RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "94a53e5ae76eda480faaad6ba357a255",
     "grade": true,
     "grade_id": "ex_2",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ['Spring quarter', 'Learning spark basics', 'Big data analytics with Spark']\n",
      "Correct Output: [['Spring', 'quarter'], ['Learning', 'spark', 'basics'], ['Big', 'data', 'analytics', 'with', 'Spark']]\n",
      "Great Job!\n",
      "\n",
      "Input: ['Do not go gentle', 'into that good night', 'old age should burn and rave']\n",
      "Correct Output: [['Do', 'not', 'go', 'gentle'], ['into', 'that', 'good', 'night'], ['old', 'age', 'should', 'burn', 'and', 'rave']]\n",
      "Great Job!\n",
      "\n",
      "Input: ['do', 'I dare disturb', 'the universe', 'there will be time there will be', 'time']\n",
      "Correct Output: [['do'], ['I', 'dare', 'disturb'], ['the', 'universe'], ['there', 'will', 'be', 'time', 'there', 'will', 'be'], ['time']]\n",
      "Great Job!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import Tester.SparkBasics1 as SparkBasics1\n",
    "SparkBasics1.exercise1_2(pickleFile, mapwords, sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c6e0dfc6ef9f72c5738386464f5a938d",
     "grade": false,
     "grade_id": "r9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Exercise 3\n",
    "\n",
    "Write a function **getMax** that uses **reduce** to find the maximum number from a list of numbers. \n",
    "\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "RDD=sc.parallelize([0,2,1])\n",
    "print getMax(RDD)\n",
    "```\n",
    "\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    "2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "def getMax(C):\n",
    "    RDD = C.reduce(lambda a,b: max(a,b))\n",
    "    return RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "527ebe2d4d242bb8708ee9eadd7847f0",
     "grade": true,
     "grade_id": "ex_3",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0, 4, 2, 3, 1]\n",
      "Correct Output: 4\n",
      "Great Job!\n",
      "\n",
      "Input: [-3.2, -3.233, -3.1, -3.9]\n",
      "Correct Output: -3.1\n",
      "Great Job!\n",
      "\n",
      "Input: [2, 2, 2, 2, 2, 2]\n",
      "Correct Output: 2\n",
      "Great Job!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import Tester.SparkBasics1 as SparkBasics1\n",
    "SparkBasics1.exercise1_3(pickleFile, getMax, sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2f8fdf7150154f9b563bfa4556f48e14",
     "grade": false,
     "grade_id": "r10",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Exercise 4\n",
    "\n",
    "Write a function called **reducewords** that uses **reduce** to create a single string which is the concatenation of all the strings in stringRDD(with a space between each string). Example:\n",
    "\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "stringRDD=sc.parallelize([\"Spring quarter\", \"Learning spark basics\", \"Big data analytics with Spark\"])\n",
    "print reducewords(stringRDD)\n",
    "```\n",
    "\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    "'Spring quarter Learning spark basics Big data analytics with Spark'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "def reducewords(stringRDD):\n",
    "    RDD = stringRDD.reduce(lambda x,y: x+' '+y)\n",
    "    return RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5040444c2e6480830adb7e459bb9db0a",
     "grade": true,
     "grade_id": "ex_4",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ['Spring quarter', 'Learning spark basics', 'Big data analytics with Spark']\n",
      "Correct Output: Spring quarter Learning spark basics Big data analytics with Spark\n",
      "Great Job!\n",
      "\n",
      "Input: ['Do not go gentle', 'into that good night', 'old age should burn and rave']\n",
      "Correct Output: Do not go gentle into that good night old age should burn and rave\n",
      "Great Job!\n",
      "\n",
      "Input: ['do', 'I dare disturb', 'the universe', 'there will be time there will be', 'time']\n",
      "Correct Output: do I dare disturb the universe there will be time there will be time\n",
      "Great Job!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import Tester.SparkBasics1 as SparkBasics1\n",
    "SparkBasics1.exercise1_4(pickleFile, reducewords, sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "da12ed801c802a0d343f89edc233fc03",
     "grade": false,
     "grade_id": "r11",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Exercise 5\n",
    "\n",
    "Write a non-Spark function **maxFunc** that when called by the **reduce** command outputs the maximum element from a set of lists.\n",
    "\n",
    "######  <span style=\"color:blue\">Code:</span>\n",
    "```python\n",
    "listRDD=sc.parallelize([[3,4],[2,1],[7,9]])\n",
    "print listRDD.reduce(maxFunc)\n",
    "```\n",
    "\n",
    "######  <span style=\"color:magenta\">Output:</span>\n",
    " [9]\n",
    "\n",
    "     Note: The output is a list containing a single number rather than just a single number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\n"
     ]
    }
   ],
   "source": [
    "# Modify this cell\n",
    "listRDD=sc.parallelize([[3,4],[2,1],[7,9]])\n",
    "def maxFunc(x,y):\n",
    "    top = []\n",
    "    x = np.max(x)\n",
    "    y = np.max(y)\n",
    "    if x > y: \n",
    "        top.append(x)\n",
    "        return top\n",
    "    else: \n",
    "        top.append(y)\n",
    "        return top\n",
    "print listRDD.reduce(maxFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3578507332d264c0043cdff5473a744c",
     "grade": true,
     "grade_id": "ex_5",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [[15, 20], [21, 14], [18, 4, 20]]\n",
      "Correct Output: [21]\n",
      "Great Job!\n",
      "\n",
      "Input: [[3, 4, 5, -3, 19], [19.1], [7, -11]]\n",
      "Correct Output: [19.1]\n",
      "Great Job!\n",
      "\n",
      "Input: [[-3.2, -3.233, -3.9], [-4], [-3, -5]]\n",
      "Correct Output: [-3]\n",
      "Great Job!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import Tester.SparkBasics1 as SparkBasics1\n",
    "SparkBasics1.exercise1_5(pickleFile, maxFunc, sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "54aeb98a1c64f24ebde33767001721da",
     "grade": false,
     "grade_id": "r12",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "174px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
